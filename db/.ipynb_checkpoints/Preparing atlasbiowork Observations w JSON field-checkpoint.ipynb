{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, json, math\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obs.models import Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for observations that are keyed to existing sites\n",
    "see Geometry notebook for creating new sites from lat, long columns.\n",
    "\n",
    "Data procedure: \n",
    "1. First get sites into db with Geometry notebook. \n",
    "2. Then get photos (see Retrieving photos notebook for grabbing them from urls, and so you can give photos filenames that can be associated with observations by id or something).\n",
    "3. Lastly, format the data with JSON field. This can include URLs for photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sampleID                 object\n",
       "site_id                   int64\n",
       "type_id                   int64\n",
       "observer_id               int64\n",
       "parentobs_id              int64\n",
       "analysis                 object\n",
       "lab                      object\n",
       "date_analyzed    datetime64[ns]\n",
       "unit2                    object\n",
       "value2                  float64\n",
       "unit1                    object\n",
       "value1                  float64\n",
       "unit3                    object\n",
       "value3                  float64\n",
       "analysisNote             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Twin Rivers (Aug 2017).xls')\n",
    "#watch out for missing or blank fields, do cleanup as needed\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'site_description':'description','date':'olddate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add foreign key fields for atlasbiowork Observation model\n",
    "df['observer_id'] = 1 # this is my observer_id\n",
    "df.rename(columns={'pk':'site_id'}, inplace=True)\n",
    "df['type_id'] = 19 #for infiltration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect timings columns in format 'mm:ss, mm:ss, mm:ss'\n",
    "#convert decimal minutes to mm:ss\n",
    "def pad(n):\n",
    "    if n > 0:\n",
    "        return str(math.floor(n)) + ':' + str.zfill(str(math.floor((n % 1)*60)),2)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "timing_cols=['ring_1:inf_time1','ring_1:inf_time2','ring_1:inf_time3','ring_1:inf_time4']   \n",
    "for i, row in df[timing_cols].iterrows():\n",
    "    l = list(row)\n",
    "    m = list(pad(value) for value in l if not math.isnan(value))\n",
    "    df.loc[i,'timings_1'] = ', '.join(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sampleID          object\n",
       "site_id            int64\n",
       "type_id            int64\n",
       "observer_id        int64\n",
       "parentobs_id       int64\n",
       "analysis          object\n",
       "lab               object\n",
       "date_analyzed     object\n",
       "unit2             object\n",
       "value2           float64\n",
       "unit1             object\n",
       "value1           float64\n",
       "unit3             object\n",
       "value3           float64\n",
       "analysisNote      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need YYYY-MM-DD format as string for the JSON field\n",
    "df['date_analyzed'] = pd.to_datetime(df['date_analyzed']).dt.strftime('%Y-%m-%d')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this next part is tricky. Must use JSON functions, not to_dict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_values=['sampleID','analysis', 'lab', 'date_analyzed', 'unit2', 'value2', 'unit1',\n",
    "       'value1', 'unit3', 'value3', 'analysisNote']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_values = analysis_values\n",
    "#infil_values = ['timings_1','description','date']#columns for JSON values field for this datatype.\n",
    "s = df[my_values].to_json(orient='records')\n",
    "t = pd.Series(json.loads(s))\n",
    "v = pd.DataFrame(t, columns=['values'])\n",
    "#now we have a JSON values field that we can add to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce unneeded columns\n",
    "df= df[['site_id',\n",
    "       'observer_id', 'type_id','parentobs_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in the values columns. The indexes should correspond since they are from the same df\n",
    "df = df.merge(v, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site_id', 'observer_id', 'type_id', 'parentobs_id', 'values'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it for good measure\n",
    "df.to_csv('infiltrationNEW.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= red>WARNING: db operation ahead</font>\n",
    "don't use bulk_create. Values field has to be a dict, not a str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site_id                                                       462\n",
       "observer_id                                                    45\n",
       "type_id                                                        33\n",
       "parentobs_id                                                 4450\n",
       "values          {'sampleID': 'TR1A', 'unit3': 'total organic c...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now this seems to work!!!\n",
    "for row in df.itertuples():\n",
    "    p = Observation(\n",
    "        site_id=row[1],\n",
    "        observer_id=row[2],\n",
    "        type_id=row[3],\n",
    "        parentobs_id=row[4],\n",
    "        values=row[5])\n",
    "    #p.save()  #UNCOMMENT AT YOUR PERIL!!!! \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
